{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import legendre\n",
    "from numpy.linalg import svd\n",
    "\n",
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def superposition(data):\n",
    "    scale=StandardScaler()\n",
    "    \n",
    "\n",
    "    scaled = scale.fit_transform(data)\n",
    "    sum=np.zeros((5000,5000))\n",
    "    x = np.linspace(-1,1,5000)\n",
    "    for i in range(data.shape[1]):\n",
    "        sum=sum+np.outer(data[:,i],legendre(i+1)(x))\n",
    "    \n",
    "    return sum\n",
    "\n",
    "def singularvaluedecomposition(data):\n",
    "    data_sup = superposition(data)\n",
    "    a, data_svd, b = svd(data_sup)\n",
    "\n",
    "    return data_svd\n",
    "\n",
    "def normalize_matrix(matrix):\n",
    "    matrix_norm = np.linalg.norm(matrix, 'fro')\n",
    "\n",
    "    if np.isnan(matrix_norm):\n",
    "        return np.zeros_like(matrix)\n",
    "    else:\n",
    "        normalized_matrix = matrix / matrix_norm\n",
    "        return normalized_matrix\n",
    "    \n",
    "def coarse_grain(data,f):\n",
    "    img = superposition(data)\n",
    "    s1=np.zeros((int(img.shape[0]/f),int(img.shape[1]/f))) # Coarse grained image\n",
    "    for i in range(s1.shape[0]):\n",
    "        for j in range(s1.shape[1]):\n",
    "            s1[i,j]=np.mean(img[i*f:i*f+f,j*f:j*f+f]) \n",
    "\n",
    "    return s1\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "data = load('disease_SR.npy')\n",
    "cc = coarse_grain(data[0],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('junk.txt',cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224.64094376564026\n",
      "209.28906917572021\n",
      "209.50033831596375\n",
      "209.37157154083252\n",
      "209.83711552619934\n",
      "209.5396704673767\n",
      "209.0870645046234\n",
      "209.55457520484924\n",
      "209.30322933197021\n",
      "209.39234614372253\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "    \n",
    "#### SR data\n",
    "\n",
    "data = load('disease_SR.npy')\n",
    "\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    for j in range(len(cc)):\n",
    "        norm_matrix.append(normalize_matrix(cc[j]))\n",
    "\n",
    "        \n",
    "\n",
    "    cc = norm_matrix\n",
    "\n",
    "    start = time()\n",
    "    results = Parallel(n_jobs = 10)(delayed(coarse_grain)(x,50) for x in cc)\n",
    "    end = time()\n",
    "\n",
    "    print(end- start)\n",
    "\n",
    "    results = np.array(results)\n",
    "    cc = []\n",
    "    for j in range(results.shape[0]):\n",
    "        cc.append(results[j].ravel())\n",
    "\n",
    "    np.savetxt('disease_SR_svd' + '_'+str(i) + '.txt',cc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209.2899248600006\n",
      "208.90706539154053\n",
      "209.42468357086182\n",
      "209.34997653961182\n",
      "209.53325629234314\n",
      "209.5820450782776\n",
      "209.33673214912415\n",
      "209.38219451904297\n",
      "209.40095925331116\n",
      "209.59953713417053\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "    \n",
    "#### SB data\n",
    "    \n",
    "data = load('disease_SB.npy')\n",
    "\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    for j in range(len(cc)):\n",
    "        norm_matrix.append(normalize_matrix(cc[j]))\n",
    "\n",
    "    cc = norm_matrix\n",
    "\n",
    "    start = time()\n",
    "    results = Parallel(n_jobs = 10)(delayed(coarse_grain)(x,50) for x in cc)\n",
    "    end = time()\n",
    "\n",
    "    print(end- start)\n",
    "    results = np.array(results)\n",
    "    cc = []\n",
    "    for j in range(results.shape[0]):\n",
    "        cc.append(results[j].ravel())\n",
    "    np.savetxt('disease_SB_svd' + '_'+str(i) + '.txt',cc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209.02064037322998\n",
      "208.82528924942017\n",
      "209.06516313552856\n",
      "208.73888397216797\n",
      "209.12845993041992\n",
      "208.70458269119263\n",
      "208.95306205749512\n",
      "208.54008150100708\n",
      "209.3042025566101\n",
      "208.6762990951538\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "    \n",
    "#### SB data\n",
    "    \n",
    "data = load('disease_ST.npy')\n",
    "\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    for j in range(len(cc)):\n",
    "        norm_matrix.append(normalize_matrix(cc[j]))\n",
    "\n",
    "    cc = norm_matrix\n",
    "    \n",
    "    start = time()\n",
    "    results = Parallel(n_jobs = 10)(delayed(coarse_grain)(x,50) for x in cc)\n",
    "    end = time()\n",
    "\n",
    "    print(end- start)\n",
    "\n",
    "    results = np.array(results)\n",
    "    cc = []\n",
    "    for j in range(results.shape[0]):\n",
    "        cc.append(results[j].ravel())\n",
    "    np.savetxt('disease_ST_svd' + '_'+str(i) + '.txt',cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
