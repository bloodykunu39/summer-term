{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of cores : 80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "num_workers = os.cpu_count()\n",
    "print(f'No of cores : {num_workers}')\n",
    "\n",
    "num_workers = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4940.710018396378\n",
      "4898.314198255539\n",
      "4854.849999189377\n",
      "4860.443804264069\n",
      "4839.3209590911865\n",
      "4866.007040262222\n",
      "4865.296958446503\n",
      "4703.115574598312\n",
      "4687.654863357544\n",
      "4644.396667003632\n",
      "4639.330739021301\n",
      "4644.153234004974\n",
      "4823.494122266769\n",
      "4739.5876705646515\n",
      "4644.712918043137\n",
      "4960.661412715912\n",
      "4882.312167406082\n",
      "5004.132046461105\n",
      "4895.21014714241\n",
      "4907.332421064377\n",
      "4917.467230796814\n",
      "4898.814135313034\n",
      "4912.068798303604\n",
      "4918.8691663742065\n",
      "4892.8863043785095\n",
      "4905.698025465012\n",
      "4892.356979846954\n",
      "4889.421500205994\n",
      "4909.269555807114\n",
      "4884.938406467438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import legendre\n",
    "from numpy.linalg import svd\n",
    "\n",
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def superposition(data):\n",
    "    scale=StandardScaler()\n",
    "    \n",
    "\n",
    "    scaled = scale.fit_transform(data)\n",
    "    sum=np.zeros((5000,5000))\n",
    "    x = np.linspace(-1,1,5000)\n",
    "    for i in range(data.shape[1]):\n",
    "        sum=sum+np.outer(data[:,i],legendre(i+1)(x))\n",
    "    \n",
    "    return sum\n",
    "\n",
    "def singularvaluedecomposition(data):\n",
    "    data_sup = superposition(data)\n",
    "    a, data_svd, b = svd(data_sup)\n",
    "\n",
    "    return data_svd\n",
    "\n",
    "def normalize_matrix(matrix):\n",
    "    matrix_norm = np.linalg.norm(matrix, 'fro')\n",
    "\n",
    "    if np.isnan(matrix_norm):\n",
    "        return np.zeros_like(matrix)\n",
    "    else:\n",
    "        normalized_matrix = matrix / matrix_norm\n",
    "        return normalized_matrix\n",
    "\n",
    "    \n",
    "\n",
    "############################################################\n",
    "    \n",
    "#### SR data\n",
    "\n",
    "data = load('disease_SR.npy')\n",
    "\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    for j in range(len(cc)):\n",
    "        norm_matrix.append(normalize_matrix(cc[j]))\n",
    "\n",
    "        \n",
    "\n",
    "    cc = norm_matrix\n",
    "\n",
    "    start = time()\n",
    "    results = Parallel(n_jobs = 10)(delayed(singularvaluedecomposition)(x) for x in cc)\n",
    "    end = time()\n",
    "\n",
    "    print(end- start)\n",
    "\n",
    "    np.savetxt('disease_SR_svd' + '_'+str(i) + '.txt',results)\n",
    "\n",
    "\n",
    "############################################################\n",
    "    \n",
    "#### SB data\n",
    "    \n",
    "data = load('disease_SB.npy')\n",
    "\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    for j in range(len(cc)):\n",
    "        norm_matrix.append(normalize_matrix(cc[j]))\n",
    "\n",
    "    cc = norm_matrix\n",
    "\n",
    "    start = time()\n",
    "    results = Parallel(n_jobs = 10)(delayed(singularvaluedecomposition)(x) for x in cc)\n",
    "    end = time()\n",
    "\n",
    "    print(end- start)\n",
    "\n",
    "    np.savetxt('disease_SB_svd' + '_'+str(i) + '.txt',results)\n",
    "\n",
    "\n",
    "############################################################\n",
    "    \n",
    "#### SB data\n",
    "    \n",
    "data = load('disease_ST.npy')\n",
    "\n",
    "split_number = 10\n",
    "if len(data)%split_number == 0:\n",
    "    data_split = np.array_split(data,split_number)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(split_number):\n",
    "    cc = data_split[i]\n",
    "\n",
    "    norm_matrix = []\n",
    "    for j in range(len(cc)):\n",
    "        norm_matrix.append(normalize_matrix(cc[j]))\n",
    "\n",
    "    cc = norm_matrix\n",
    "    \n",
    "    start = time()\n",
    "    results = Parallel(n_jobs = 10)(delayed(singularvaluedecomposition)(x) for x in cc)\n",
    "    end = time()\n",
    "\n",
    "    print(end- start)\n",
    "    np.savetxt('disease_ST_svd' + '_'+str(i) + '.txt',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
