{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beginning of pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning (ML) and Deep Learning (DL) are both subfields of Artificial Intelligence (AI) that involve training models to make predictions or perform tasks based on data. However, there are some key differences between ML and DL:\n",
    "\n",
    "1. **Representation of Data**: In ML, data is typically represented using handcrafted features that are extracted from the raw data. These features are then used as input to the ML model. In DL, the model learns to automatically extract features from the raw data, eliminating the need for manual feature engineering.\n",
    "\n",
    "2. **Model Complexity**: ML models are usually simpler and have fewer parameters compared to DL models. DL models, on the other hand, are more complex and have a larger number of parameters. This allows DL models to learn more intricate patterns and relationships in the data.\n",
    "\n",
    "3. **Training Data Size**: ML models can perform well with smaller training datasets. DL models, on the other hand, typically require larger amounts of training data to generalize effectively. DL models thrive on big data and can benefit from large-scale datasets.\n",
    "\n",
    "4. **Computational Requirements**: DL models are computationally more intensive compared to ML models. DL models often require specialized hardware, such as Graphics Processing Units (GPUs), to train efficiently. ML models can be trained on standard hardware.\n",
    "\n",
    "5. **Domain Expertise**: ML models often require domain expertise to engineer relevant features and select appropriate algorithms. DL models, on the other hand, can automatically learn features from the data, reducing the need for extensive domain knowledge.\n",
    "\n",
    "6. **Interpretability**: ML models are generally more interpretable compared to DL models. ML models often provide insights into the importance of different features and how they contribute to the predictions. DL models, due to their complexity, are often considered as \"black boxes\" and provide less interpretability.\n",
    "\n",
    "It's important to note that ML and DL are not mutually exclusive, and DL is a subset of ML. DL techniques, such as deep neural networks, have shown remarkable success in various domains, including computer vision, natural language processing, and speech recognition. However, ML techniques still have their place in scenarios where interpretability, smaller datasets, or limited computational resources are important considerations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector\n",
    "vec=torch.tensor([1.0,2.0,3.0,4.0,5.0])\n",
    "vec.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create matrix\n",
    "mat=torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "print(mat)\n",
    "mat.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3d tensor\n",
    "tens=torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "print(tens)\n",
    "tens.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.,  2.],\n",
      "          [ 3.,  4.]],\n",
      "\n",
      "         [[ 5.,  6.],\n",
      "          [ 7.,  8.]]],\n",
      "\n",
      "\n",
      "        [[[ 9., 10.],\n",
      "          [11., 12.]],\n",
      "\n",
      "         [[13., 14.],\n",
      "          [15., 16.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4d tensor\n",
    "tens4d=torch.tensor([[[[1.0,2.0],[3.0,4.0]],[[5.0,6.0],[7.0,8.0]]],[[[9.0,10.0],[11.0,12.0]],[[13.0,14.0],[15.0,16.0]]]])\n",
    "print(tens4d)\n",
    "tens.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2751, 0.3309],\n",
       "         [0.0969, 0.7469],\n",
       "         [0.4730, 0.4074]],\n",
       "\n",
       "        [[0.2959, 0.0028],\n",
       "         [0.4532, 0.9231],\n",
       "         [0.8467, 0.6553]],\n",
       "\n",
       "        [[0.4918, 0.9490],\n",
       "         [0.0654, 0.3991],\n",
       "         [0.3111, 0.3516]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rand3dtensor=torch.rand(3,3,2)#create a random 3d tensor\n",
    "rand3dtensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand3dtensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[9.5775e-02, 5.3850e-01, 5.8156e-01, 2.3919e-01, 5.3811e-01,\n",
       "            3.5715e-01],\n",
       "           [3.0752e-01, 7.2882e-01, 4.8394e-01, 1.6214e-01, 9.3413e-01,\n",
       "            6.6962e-01],\n",
       "           [2.0804e-01, 1.3911e-01, 6.7715e-01, 1.5241e-01, 1.7841e-01,\n",
       "            1.1562e-01],\n",
       "           [5.6969e-01, 5.5312e-01, 4.9397e-01, 4.1216e-01, 8.3389e-01,\n",
       "            9.0965e-01],\n",
       "           [3.0470e-01, 1.5882e-01, 8.5260e-01, 9.4303e-01, 6.4691e-01,\n",
       "            2.4861e-01]],\n",
       "\n",
       "          [[6.9817e-01, 9.4190e-01, 8.0178e-01, 9.6321e-04, 8.7296e-01,\n",
       "            5.8363e-02],\n",
       "           [2.6293e-01, 9.1104e-01, 6.6351e-01, 8.9925e-01, 1.5148e-01,\n",
       "            3.8147e-01],\n",
       "           [5.7087e-01, 7.6348e-01, 8.5531e-01, 4.4312e-01, 3.0807e-01,\n",
       "            7.3935e-01],\n",
       "           [1.1277e-01, 1.9859e-01, 5.7023e-01, 7.4033e-01, 2.5312e-02,\n",
       "            5.4974e-01],\n",
       "           [6.0333e-01, 1.7152e-01, 1.7703e-01, 9.8963e-01, 3.8065e-01,\n",
       "            1.9811e-01]],\n",
       "\n",
       "          [[2.7767e-01, 4.3394e-01, 9.3104e-01, 4.0679e-01, 1.8775e-01,\n",
       "            4.5389e-01],\n",
       "           [1.3795e-01, 4.5814e-01, 9.5183e-01, 8.8655e-01, 4.4752e-01,\n",
       "            1.4976e-01],\n",
       "           [9.8480e-01, 1.3581e-01, 4.6709e-01, 5.2936e-01, 7.0409e-01,\n",
       "            4.9721e-01],\n",
       "           [2.3774e-01, 8.3254e-01, 4.5936e-01, 6.7405e-02, 2.4850e-01,\n",
       "            8.0631e-01],\n",
       "           [8.1329e-01, 7.9008e-01, 7.3265e-01, 8.2254e-01, 3.6045e-01,\n",
       "            9.7768e-01]],\n",
       "\n",
       "          [[9.8681e-02, 6.1125e-01, 1.2790e-01, 9.1462e-01, 9.2191e-01,\n",
       "            8.2069e-01],\n",
       "           [1.8354e-01, 5.9815e-02, 4.7664e-01, 5.7930e-02, 4.5116e-01,\n",
       "            4.0253e-01],\n",
       "           [3.6236e-01, 9.5925e-01, 6.5389e-01, 5.5673e-01, 2.2455e-01,\n",
       "            4.2614e-01],\n",
       "           [6.6306e-01, 5.1020e-01, 3.0572e-01, 7.9216e-01, 9.8045e-01,\n",
       "            6.7114e-01],\n",
       "           [7.3520e-01, 9.6170e-01, 7.9553e-02, 3.1494e-01, 1.5666e-01,\n",
       "            8.8097e-01]]],\n",
       "\n",
       "\n",
       "         [[[1.2155e-01, 8.5033e-01, 8.8579e-01, 2.6784e-01, 3.6993e-01,\n",
       "            4.0060e-01],\n",
       "           [9.3675e-01, 8.8289e-01, 3.9189e-01, 6.5610e-01, 7.2337e-01,\n",
       "            9.7186e-01],\n",
       "           [9.5399e-01, 7.3930e-01, 3.2141e-01, 1.5965e-01, 6.3599e-01,\n",
       "            1.2244e-02],\n",
       "           [6.2416e-01, 2.8844e-01, 6.8645e-01, 2.1112e-01, 4.2554e-01,\n",
       "            2.8572e-01],\n",
       "           [8.1983e-01, 4.3444e-01, 5.0103e-01, 1.8207e-01, 3.7632e-01,\n",
       "            2.5127e-01]],\n",
       "\n",
       "          [[1.0751e-01, 6.1078e-01, 9.4346e-01, 3.7660e-01, 3.7971e-01,\n",
       "            7.8522e-01],\n",
       "           [3.9887e-01, 8.2707e-01, 1.3136e-01, 5.6742e-01, 5.8324e-01,\n",
       "            8.8089e-02],\n",
       "           [9.4113e-01, 6.6782e-01, 2.5710e-02, 6.5540e-01, 3.8333e-01,\n",
       "            3.2031e-01],\n",
       "           [3.1577e-01, 5.6961e-01, 7.5795e-01, 7.1065e-02, 2.3500e-01,\n",
       "            3.6739e-01],\n",
       "           [4.3516e-01, 3.8691e-01, 8.6867e-01, 4.7007e-01, 9.4456e-01,\n",
       "            1.9130e-02]],\n",
       "\n",
       "          [[3.2964e-01, 3.7727e-01, 1.7166e-01, 9.2748e-01, 5.7679e-01,\n",
       "            7.6034e-02],\n",
       "           [4.2638e-01, 9.8083e-01, 3.8862e-01, 4.0558e-01, 8.7086e-02,\n",
       "            9.1328e-01],\n",
       "           [6.9449e-01, 9.0106e-01, 4.0831e-01, 6.2802e-02, 9.6926e-01,\n",
       "            7.5827e-01],\n",
       "           [9.8080e-01, 8.2322e-01, 5.2079e-01, 6.7158e-01, 8.2408e-01,\n",
       "            1.2772e-01],\n",
       "           [6.3192e-01, 8.9950e-01, 2.0908e-01, 5.0086e-01, 4.2638e-02,\n",
       "            3.7215e-01]],\n",
       "\n",
       "          [[8.5904e-01, 6.7055e-02, 4.4619e-02, 7.6260e-01, 2.0812e-01,\n",
       "            6.5803e-02],\n",
       "           [6.2600e-01, 9.8365e-01, 4.6419e-01, 9.9930e-01, 9.9413e-02,\n",
       "            4.0335e-01],\n",
       "           [4.3470e-01, 6.2837e-02, 8.4833e-01, 7.3226e-01, 7.2438e-01,\n",
       "            4.0740e-01],\n",
       "           [4.5859e-01, 2.2000e-01, 5.2866e-01, 4.7348e-01, 4.2592e-01,\n",
       "            7.0264e-01],\n",
       "           [3.2815e-01, 8.6781e-01, 1.3497e-01, 6.1832e-01, 7.7950e-01,\n",
       "            7.1464e-01]]],\n",
       "\n",
       "\n",
       "         [[[8.2028e-01, 8.1578e-01, 1.7877e-01, 2.2639e-01, 7.3871e-01,\n",
       "            9.1088e-01],\n",
       "           [5.4013e-01, 7.9555e-01, 5.5986e-01, 6.8651e-01, 6.9783e-01,\n",
       "            2.2910e-01],\n",
       "           [7.3963e-01, 8.6955e-01, 1.5540e-01, 6.9383e-01, 2.5968e-01,\n",
       "            5.4211e-01],\n",
       "           [2.7694e-01, 2.4515e-01, 4.5046e-01, 1.6956e-02, 9.4771e-01,\n",
       "            5.8012e-01],\n",
       "           [4.4764e-01, 7.4435e-01, 9.3549e-01, 5.7323e-01, 8.8248e-01,\n",
       "            6.1125e-01]],\n",
       "\n",
       "          [[6.9748e-01, 1.5850e-01, 2.3685e-01, 8.7408e-01, 2.4762e-01,\n",
       "            8.1127e-01],\n",
       "           [9.6302e-01, 6.8134e-01, 3.1730e-01, 1.8913e-01, 4.2438e-02,\n",
       "            6.3073e-01],\n",
       "           [4.3977e-01, 5.0465e-01, 3.0885e-01, 1.1105e-01, 7.1367e-01,\n",
       "            4.6792e-01],\n",
       "           [7.8667e-01, 7.7237e-01, 9.3335e-01, 3.5125e-01, 7.0376e-02,\n",
       "            2.6320e-01],\n",
       "           [2.3137e-01, 7.0824e-01, 1.4944e-01, 6.3966e-01, 9.0434e-01,\n",
       "            7.3255e-01]],\n",
       "\n",
       "          [[7.1663e-01, 6.0611e-01, 5.2625e-01, 1.3309e-01, 3.4940e-01,\n",
       "            1.1030e-01],\n",
       "           [1.0390e-01, 3.5920e-01, 1.0914e-01, 6.8426e-01, 1.0684e-01,\n",
       "            2.0598e-01],\n",
       "           [5.8509e-01, 9.9587e-01, 6.8079e-01, 1.5970e-02, 2.0651e-01,\n",
       "            2.6673e-01],\n",
       "           [3.3943e-01, 9.8812e-01, 3.5055e-01, 9.2447e-01, 9.3911e-01,\n",
       "            5.3215e-01],\n",
       "           [3.6197e-01, 1.2995e-01, 7.1593e-02, 9.6842e-01, 8.9364e-01,\n",
       "            9.6034e-01]],\n",
       "\n",
       "          [[5.2290e-01, 5.6380e-01, 5.2729e-01, 6.8159e-01, 6.2511e-01,\n",
       "            5.1801e-01],\n",
       "           [1.9341e-01, 8.9509e-02, 2.3164e-01, 7.5147e-01, 2.0587e-01,\n",
       "            8.7886e-01],\n",
       "           [3.2051e-01, 5.8163e-01, 4.6139e-01, 5.8004e-01, 3.4303e-01,\n",
       "            6.7188e-01],\n",
       "           [7.2420e-01, 2.1857e-01, 3.7737e-01, 3.3628e-01, 4.8841e-01,\n",
       "            5.4516e-01],\n",
       "           [6.5321e-01, 6.0581e-01, 7.9840e-01, 7.8440e-01, 8.3651e-01,\n",
       "            4.8294e-02]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[7.9159e-01, 1.9397e-01, 8.6099e-02, 8.2564e-02, 2.2768e-01,\n",
       "            3.0816e-01],\n",
       "           [3.6479e-03, 4.1490e-01, 9.9919e-01, 4.6717e-01, 6.5605e-01,\n",
       "            6.0754e-01],\n",
       "           [4.9322e-01, 1.9571e-02, 6.4189e-01, 6.9661e-02, 5.3098e-01,\n",
       "            7.5471e-01],\n",
       "           [3.5661e-01, 1.9183e-01, 5.4343e-02, 4.6432e-01, 9.8215e-02,\n",
       "            1.0545e-02],\n",
       "           [7.1348e-01, 6.8604e-01, 3.9520e-01, 4.1474e-01, 3.0447e-03,\n",
       "            1.8671e-01]],\n",
       "\n",
       "          [[8.0698e-01, 8.9765e-01, 3.7616e-01, 9.7128e-01, 6.1380e-01,\n",
       "            2.1559e-02],\n",
       "           [8.0607e-01, 1.4486e-01, 7.3045e-01, 1.6211e-01, 2.4111e-01,\n",
       "            2.4985e-01],\n",
       "           [6.8992e-01, 4.7892e-01, 2.8586e-01, 7.4875e-01, 6.4393e-01,\n",
       "            6.6762e-01],\n",
       "           [1.2878e-01, 6.4431e-01, 3.6820e-01, 8.2096e-01, 9.2910e-02,\n",
       "            7.2325e-01],\n",
       "           [6.1210e-01, 3.4542e-01, 3.3880e-01, 7.6695e-01, 4.0265e-01,\n",
       "            1.1094e-01]],\n",
       "\n",
       "          [[6.5867e-01, 1.1486e-01, 7.9119e-01, 2.5933e-01, 7.2631e-01,\n",
       "            8.0626e-01],\n",
       "           [3.2367e-01, 4.7668e-01, 3.8491e-01, 6.5062e-01, 1.8484e-01,\n",
       "            3.9849e-01],\n",
       "           [7.3965e-01, 3.0207e-02, 7.3499e-01, 2.3752e-01, 3.9968e-01,\n",
       "            2.8435e-01],\n",
       "           [6.1985e-01, 5.8169e-01, 3.7861e-02, 2.5224e-01, 1.9644e-01,\n",
       "            7.2621e-01],\n",
       "           [3.4017e-01, 6.8375e-01, 2.3852e-01, 1.1835e-01, 9.7215e-01,\n",
       "            5.1570e-01]],\n",
       "\n",
       "          [[6.0485e-01, 1.7615e-01, 9.1723e-01, 8.5373e-01, 8.8506e-01,\n",
       "            1.1312e-01],\n",
       "           [5.6389e-01, 4.9937e-01, 6.3436e-01, 4.3525e-01, 6.3877e-01,\n",
       "            9.7126e-01],\n",
       "           [2.0739e-01, 1.0959e-01, 6.4158e-01, 6.4434e-01, 1.4665e-01,\n",
       "            1.0032e-01],\n",
       "           [7.6475e-01, 6.3124e-01, 8.6647e-01, 3.4620e-02, 3.3021e-01,\n",
       "            2.1774e-01],\n",
       "           [8.6345e-01, 4.4056e-01, 8.5594e-01, 4.9636e-01, 3.9027e-01,\n",
       "            6.4397e-01]]],\n",
       "\n",
       "\n",
       "         [[[1.2934e-01, 9.6622e-01, 6.5788e-01, 1.0809e-01, 5.2586e-01,\n",
       "            6.9320e-01],\n",
       "           [3.7887e-01, 7.5927e-02, 5.3203e-01, 1.6240e-01, 8.0678e-01,\n",
       "            1.1490e-01],\n",
       "           [8.1153e-01, 4.4466e-01, 1.2881e-01, 1.9888e-01, 4.5623e-01,\n",
       "            2.2806e-01],\n",
       "           [7.5444e-01, 6.2788e-01, 5.3730e-01, 7.1680e-01, 8.4927e-01,\n",
       "            4.8820e-01],\n",
       "           [6.9010e-01, 6.4188e-01, 8.6332e-01, 5.0727e-01, 5.9817e-01,\n",
       "            5.3548e-02]],\n",
       "\n",
       "          [[3.9114e-01, 6.5032e-01, 3.3572e-01, 4.3524e-01, 8.8107e-01,\n",
       "            3.3947e-01],\n",
       "           [6.6632e-02, 6.3279e-01, 2.1452e-01, 5.8410e-01, 2.8768e-01,\n",
       "            6.0563e-01],\n",
       "           [8.4361e-02, 5.9253e-01, 6.3307e-01, 8.3989e-01, 2.4491e-01,\n",
       "            6.5186e-01],\n",
       "           [8.7939e-01, 3.4815e-01, 6.3656e-01, 9.9684e-01, 4.0738e-01,\n",
       "            9.0869e-01],\n",
       "           [6.7068e-01, 2.9288e-01, 5.2822e-01, 3.3995e-01, 3.6071e-01,\n",
       "            5.5433e-01]],\n",
       "\n",
       "          [[8.0590e-01, 8.6199e-01, 5.4126e-01, 3.6568e-01, 8.4838e-01,\n",
       "            7.4343e-01],\n",
       "           [8.7126e-01, 5.0637e-01, 3.4733e-01, 8.7610e-01, 3.8419e-01,\n",
       "            7.0440e-02],\n",
       "           [4.6956e-01, 6.1625e-02, 8.1990e-02, 1.7489e-02, 5.8337e-01,\n",
       "            6.8434e-01],\n",
       "           [5.4099e-01, 7.2427e-01, 3.4852e-01, 1.0534e-01, 3.8164e-01,\n",
       "            3.6745e-01],\n",
       "           [7.4550e-01, 3.8678e-01, 1.1698e-01, 5.2861e-01, 1.9131e-01,\n",
       "            2.2586e-01]],\n",
       "\n",
       "          [[4.5270e-01, 3.7406e-01, 7.7390e-01, 8.3086e-03, 9.4503e-03,\n",
       "            4.2440e-01],\n",
       "           [7.5614e-01, 3.8504e-01, 9.6274e-01, 1.7851e-01, 3.4650e-01,\n",
       "            3.9587e-01],\n",
       "           [6.4770e-01, 6.6067e-01, 1.5095e-01, 7.6802e-01, 9.9996e-01,\n",
       "            2.1246e-01],\n",
       "           [1.8577e-01, 3.1470e-01, 1.2514e-01, 5.8236e-01, 5.7003e-01,\n",
       "            4.4427e-02],\n",
       "           [5.5408e-01, 9.7320e-01, 5.1312e-01, 9.5607e-01, 2.2973e-01,\n",
       "            7.3011e-02]]],\n",
       "\n",
       "\n",
       "         [[[5.3293e-02, 2.3414e-01, 6.2522e-01, 4.0080e-01, 5.8839e-01,\n",
       "            3.0904e-01],\n",
       "           [3.6029e-01, 7.8114e-01, 8.2085e-01, 2.1606e-01, 8.8375e-01,\n",
       "            7.8615e-01],\n",
       "           [4.8105e-01, 3.0561e-01, 8.8136e-01, 1.4801e-01, 9.7578e-02,\n",
       "            1.1365e-01],\n",
       "           [8.3171e-01, 3.6800e-01, 9.1227e-01, 9.6208e-01, 7.0910e-01,\n",
       "            6.1573e-03],\n",
       "           [8.3133e-01, 9.5271e-01, 7.4794e-03, 4.5052e-02, 5.5174e-01,\n",
       "            4.8827e-01]],\n",
       "\n",
       "          [[4.6159e-01, 2.0536e-01, 2.3809e-02, 9.8719e-02, 2.1392e-03,\n",
       "            2.3473e-01],\n",
       "           [6.8131e-01, 7.4792e-01, 4.5300e-01, 7.0054e-01, 1.0827e-01,\n",
       "            5.4496e-01],\n",
       "           [5.9445e-01, 2.8968e-01, 2.4956e-01, 1.2005e-01, 9.5978e-01,\n",
       "            7.0158e-01],\n",
       "           [5.7552e-01, 1.6720e-01, 6.8502e-01, 2.5744e-01, 8.7197e-01,\n",
       "            5.7441e-02],\n",
       "           [6.2047e-01, 9.6264e-01, 5.0495e-01, 4.6432e-01, 8.1818e-01,\n",
       "            9.3327e-01]],\n",
       "\n",
       "          [[6.8235e-02, 7.2769e-01, 6.6351e-01, 1.9389e-01, 6.1763e-01,\n",
       "            2.0763e-01],\n",
       "           [1.0383e-01, 8.8889e-02, 6.8476e-01, 7.8976e-01, 5.6556e-01,\n",
       "            4.4578e-01],\n",
       "           [7.0767e-01, 4.6987e-01, 4.5479e-01, 8.1187e-01, 1.4380e-01,\n",
       "            4.5027e-01],\n",
       "           [1.9865e-01, 9.0497e-01, 6.1755e-01, 9.9047e-01, 2.8757e-01,\n",
       "            6.0215e-01],\n",
       "           [1.2318e-01, 9.8632e-01, 1.4795e-01, 8.0998e-01, 8.7032e-01,\n",
       "            1.8582e-01]],\n",
       "\n",
       "          [[9.3952e-01, 1.7829e-01, 5.3058e-01, 2.3342e-01, 3.6330e-01,\n",
       "            7.5313e-01],\n",
       "           [8.5360e-01, 1.5225e-02, 8.5437e-01, 6.5433e-01, 2.6669e-01,\n",
       "            8.5583e-01],\n",
       "           [3.4495e-01, 9.5942e-01, 3.2179e-01, 8.7088e-01, 2.1465e-02,\n",
       "            3.6446e-01],\n",
       "           [7.0016e-01, 8.6591e-01, 3.4053e-01, 3.1419e-01, 7.0094e-01,\n",
       "            9.0922e-01],\n",
       "           [2.3826e-01, 8.2336e-01, 7.9968e-01, 8.3907e-01, 1.7706e-01,\n",
       "            2.8855e-01]]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5d random tensor\n",
    "rand5dtensor=torch.rand(2,3,4,5,6)\n",
    "rand5dtensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zero tensor\n",
    "zero_tensor=torch.zeros(3,3,3)\n",
    "zero_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#float 16 tensor\n",
    "float16_tensor=torch.zeros(3,3,3,dtype=torch.float16)\n",
    "float16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#float 64 tensor\n",
    "float64_tensor=torch.zeros(3,3,3,dtype=torch.float64)\n",
    "float64_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor*float64_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int tensor\n",
    "int_tensor=torch.tensor([1,2,3,4,5])#default int tensor is int64\n",
    "int_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#32 bit int tensor\n",
    "int32_tensor=torch.tensor([1,2,3,4,5],dtype=torch.int32)#for 16 bit use torch.int16 and for 64 bit use torch.int64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def function to check dtype device and shape of tensor\n",
    "def describe_tensor(tensor):\n",
    "    print(f\"Shape of tensor: {tensor.shape}\")\n",
    "    print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "    print(f\"Device tensor is stored on: {tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([5])\n",
      "Datatype of tensor: torch.int32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "describe_tensor(int32_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor manipulating\n",
    "\n",
    "tensor opretions include:\n",
    "* airthmatic alzebra\n",
    "* matrix multipliction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#addition\n",
    "int_tensor=torch.tensor([1,2,3,4,5])\n",
    "int_tensor+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiplication\n",
    "int_tensor*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#by pytorch inbuilt function\n",
    "torch.add(int_tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(int_tensor,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix multiplication\n",
    "* matrix multiplication \n",
    "* elemental multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 10,  40,  90, 160, 250])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element wise multiplication\n",
    "a=torch.tensor([1,2,3,4,5])\n",
    "b=torch.tensor([10,20,30,40,50])\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) * tensor([[10, 20, 30],\n",
      "        [40, 50, 60]])\n",
      "equals:tensor([[ 10,  40,  90],\n",
      "        [160, 250, 360]])\n"
     ]
    }
   ],
   "source": [
    "# element wise multiplication in 2d tensor\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "b=torch.tensor([[10,20,30],[40,50,60]])\n",
    "print(a,'*',b,)\n",
    "print(f\"equals:{a*b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[220, 280],\n",
       "        [490, 640]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix multiplication\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])#2x3\n",
    "b=torch.tensor([[10,20],[30,40],[50,60]])#3x2\n",
    "torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stat of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([2, 3])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n",
      "Mean: 3.5\n",
      "Max: 6.0\n",
      "Min: 1.0\n",
      "Sum: 21.0\n",
      "Standard Deviation: 1.8708287477493286\n"
     ]
    }
   ],
   "source": [
    "# finding mean, max, min, sum, std 2d tensor\n",
    "def stat_tensor(tensor):\n",
    "    print(f\"Shape of tensor: {tensor.shape}\")\n",
    "    print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "    print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "    print(f\"Mean: {tensor.mean()}\")# means works on float tensor\n",
    "    print(f\"Max: {tensor.max()}\")\n",
    "    print(f\"Min: {tensor.min()}\")\n",
    "    print(f\"Sum: {tensor.sum()}\")\n",
    "    print(f\"Standard Deviation: {tensor.std()}\")\n",
    "a=torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "stat_tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([2, 3])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n",
      "Max: 6.0\n",
      "Position of Max: 5\n",
      "Min: 1.0\n",
      "Position of Min: 0\n"
     ]
    }
   ],
   "source": [
    "# finding positional max and min\n",
    "def pos_max_min(tensor):\n",
    "    print(f\"Shape of tensor: {tensor.shape}\")\n",
    "    print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "    print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "    print(f\"Max: {tensor.max()}\")\n",
    "    print(f\"Position of Max: {tensor.argmax()}\")\n",
    "    print(f\"Min: {tensor.min()}\")\n",
    "    print(f\"Position of Min: {tensor.argmin()}\")\n",
    "a=torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "pos_max_min(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshaping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped to 3,2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(\"reshaped to 3,2\")\n",
    "z=a.reshape(3,2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viewed to 3,2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view changes the shape of tensor\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(\"viewed to 3,2\")\n",
    "view_a=a.view(3,2)\n",
    "view_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial a tensor tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "chaning view_a will change a tensor([[100,   2,   3],\n",
      "        [  4,   5,   6]])\n"
     ]
    }
   ],
   "source": [
    "print(\"initial a tensor\",a)\n",
    "view_a[0,0]=100\n",
    "print(\"chaning view_a will change a\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking tensors\n",
    "a=torch.tensor([1,2,3])\n",
    "b=torch.tensor([4,5,6])\n",
    "torch.stack((a,b),dim=0)#dimention 0 means stacking row wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((a,b),dim=1)#dimention 1 means stacking column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[ 7,  8,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stacking 2d tensors to 3d tensor\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "b=torch.tensor([[7,8,9],[10,11,12]])\n",
    "torch.stack((a,b),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]]) torch.Size([1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('squezed',\n",
       " tensor([[1, 2, 3],\n",
       "         [4, 5, 6]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SQUEEZING AND UNSQUEEZING TENSORS\n",
    "a=torch.tensor([[[1,2,3],[4,5,6]]])\n",
    "print(a,a.shape)\n",
    "\"squezed\",a.squeeze(),a.squeeze().shape#removes the dimension of size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('unsqueezed',\n",
       " tensor([[[1, 2, 3],\n",
       "          [4, 5, 6]]]),\n",
       " torch.Size([1, 2, 3]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch unsquezzing\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(a,a.shape)\n",
    "\"unsqueezed\",a.unsqueeze(dim=0),a.unsqueeze(dim=0).shape#adds a dimension of size 1 at the specified position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_org shape torch.Size([2, 3, 4]) x_permute shape torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# permute - rearranges the dimensions of tensor eg: 3d tensor to 2d tensor\n",
    "x_org=torch.rand(2,3,4)#3d tensor of size 224x224x3 indicating 224x224 image with 3 channels(hieght, width, channels)\n",
    "# we permute the tensor to 3x224x224\n",
    "x_permute=x_org.permute(2,0,1)#(2=channels, 0=height, 1=width)\n",
    "print(\"x_org shape\",x_org.shape,\"x_permute shape\",x_permute.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexing and slicing\n",
    "* same as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor(5)\n",
      "tensor([[3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x=torch.arange(6).view(2,3)\n",
    "print(x)\n",
    "print(x[1,2])#indexing\n",
    "print(x[1:])#slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch tensor & numpy array\n",
    "* data in numpy ,want in pytorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* data in pytorch tensor ,want in numpy array -> `tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy to tensor\n",
    "np_array=np.arange(1.0,10.0)\n",
    "tensor=torch.from_numpy(np_array).type(torch.float32)#tensor is copy of numpy array so changing tensor will not change numpy array\n",
    "tensor,tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reproduciblity\n",
    "As you learn more about neural networks and machine learning, you'll start to discover how much randomness plays a part.\n",
    "Well, pseudorandomness that is. Because after all, as they're designed, a computer is fundamentally deterministic (each step is predictable) so the randomness they create are simulated randomness (though there is debate on this too, but since I'm not a computer scientist, I'll let you find out more yourself).\n",
    "How does this relate to neural networks and deep learning then?\n",
    "We've discussed neural networks start with random numbers to describe patterns in data (these numbers are poor descriptions) and try to improve those random numbers using tensor operations (and a few other things we haven't discussed yet) to better describe patterns in data.\n",
    "In short:\n",
    "\n",
    "`start with random numbers -> tensor operations -> try to make better (again and again and again)`\n",
    "\n",
    "Although randomness is nice and powerful, sometimes you'd like there to be a little less randomness.\n",
    "Why?\n",
    "So you can perform repeatable experiments.\n",
    "For example, you create an algorithm capable of achieving X performance.\n",
    "And then your friend tries it out to verify you're not crazy.\n",
    "How could they do such a thing?\n",
    "That's where reproducibility comes in.\n",
    "In other words, can you get the same (or very similar) results on your computer running the same code as I get on mine?\n",
    "Let's see a brief example of reproducibility in PyTorch.\n",
    "We'll start by creating two random tensors, since they're random, you'd expect them to be different right?\n",
    "has context menu\n",
    "Compose\n",
    "Karan Singh is typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reproducibility\n",
    "random_tensor_A=torch.rand(3,3)\n",
    "random_tensor_B=torch.rand(3,3)\n",
    "random_tensor_A==random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor c tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009],\n",
      "        [0.2566, 0.7936, 0.9408]]) \n",
      "Random tensor d tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009],\n",
      "        [0.2566, 0.7936, 0.9408]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build some reproducible tensor\n",
    "random_seed=42\n",
    "torch.manual_seed(random_seed)#set seed for reproducibility\n",
    "##print(\"Random tensor A\")\n",
    "random_tensor_c=torch.rand(3,3)\n",
    "torch.manual_seed(random_seed) ### we set the seed again to make sure the random tensor is reproducible###\n",
    "random_tensor_d=torch.rand(3,3)\n",
    "print(\"Random tensor c\",random_tensor_c,\"\\nRandom tensor d\",random_tensor_d)\n",
    "random_tensor_c==random_tensor_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpu acessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if cuda is available\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup device agnostic code\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of gpu's available\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### putting tensor on gpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), 'cuda')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor=torch.rand(3,3)\n",
    "tensor.device,device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move tensor to gpu\n",
    "tensor_on_gpu=tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"
     ]
    }
   ],
   "source": [
    "# tensor on gpu cant tranform into numpy\n",
    "try:\n",
    "    tensor_on_gpu.numpy() \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13318592, 0.9345981 , 0.59357965],\n",
       "       [0.86940444, 0.5677153 , 0.74109405],\n",
       "       [0.4294045 , 0.8854429 , 0.57390445]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU TENSOR YO NUMPY\n",
    "tensor_on_gpu.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
