{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beginning of pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning (ML) and Deep Learning (DL) are both subfields of Artificial Intelligence (AI) that involve training models to make predictions or perform tasks based on data. However, there are some key differences between ML and DL:\n",
    "\n",
    "1. **Representation of Data**: In ML, data is typically represented using handcrafted features that are extracted from the raw data. These features are then used as input to the ML model. In DL, the model learns to automatically extract features from the raw data, eliminating the need for manual feature engineering.\n",
    "\n",
    "2. **Model Complexity**: ML models are usually simpler and have fewer parameters compared to DL models. DL models, on the other hand, are more complex and have a larger number of parameters. This allows DL models to learn more intricate patterns and relationships in the data.\n",
    "\n",
    "3. **Training Data Size**: ML models can perform well with smaller training datasets. DL models, on the other hand, typically require larger amounts of training data to generalize effectively. DL models thrive on big data and can benefit from large-scale datasets.\n",
    "\n",
    "4. **Computational Requirements**: DL models are computationally more intensive compared to ML models. DL models often require specialized hardware, such as Graphics Processing Units (GPUs), to train efficiently. ML models can be trained on standard hardware.\n",
    "\n",
    "5. **Domain Expertise**: ML models often require domain expertise to engineer relevant features and select appropriate algorithms. DL models, on the other hand, can automatically learn features from the data, reducing the need for extensive domain knowledge.\n",
    "\n",
    "6. **Interpretability**: ML models are generally more interpretable compared to DL models. ML models often provide insights into the importance of different features and how they contribute to the predictions. DL models, due to their complexity, are often considered as \"black boxes\" and provide less interpretability.\n",
    "\n",
    "It's important to note that ML and DL are not mutually exclusive, and DL is a subset of ML. DL techniques, such as deep neural networks, have shown remarkable success in various domains, including computer vision, natural language processing, and speech recognition. However, ML techniques still have their place in scenarios where interpretability, smaller datasets, or limited computational resources are important considerations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector\n",
    "vec=torch.tensor([1.0,2.0,3.0,4.0,5.0])\n",
    "vec.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create matrix\n",
    "mat=torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "print(mat)\n",
    "mat.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3d tensor\n",
    "tens=torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "print(tens)\n",
    "tens.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.,  2.],\n",
      "          [ 3.,  4.]],\n",
      "\n",
      "         [[ 5.,  6.],\n",
      "          [ 7.,  8.]]],\n",
      "\n",
      "\n",
      "        [[[ 9., 10.],\n",
      "          [11., 12.]],\n",
      "\n",
      "         [[13., 14.],\n",
      "          [15., 16.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4d tensor\n",
    "tens4d=torch.tensor([[[[1.0,2.0],[3.0,4.0]],[[5.0,6.0],[7.0,8.0]]],[[[9.0,10.0],[11.0,12.0]],[[13.0,14.0],[15.0,16.0]]]])\n",
    "print(tens4d)\n",
    "tens.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0663, 0.1031],\n",
       "         [0.8378, 0.7191],\n",
       "         [0.3144, 0.8198]],\n",
       "\n",
       "        [[0.4626, 0.7140],\n",
       "         [0.1771, 0.1417],\n",
       "         [0.5022, 0.2153]],\n",
       "\n",
       "        [[0.5138, 0.2262],\n",
       "         [0.7789, 0.2669],\n",
       "         [0.3922, 0.5815]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rand3dtensor=torch.rand(3,3,2)#create a random 3d tensor\n",
    "rand3dtensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand3dtensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[1.1775e-01, 3.3610e-01, 9.6414e-01, 3.4187e-01, 7.8938e-01,\n",
       "            6.1696e-01],\n",
       "           [9.4790e-01, 6.9079e-01, 6.3711e-01, 3.2216e-01, 9.7201e-02,\n",
       "            7.4557e-01],\n",
       "           [2.2447e-02, 2.7903e-01, 5.9599e-01, 5.6379e-01, 1.0914e-01,\n",
       "            7.3107e-01],\n",
       "           [4.3678e-01, 4.3996e-01, 6.1661e-01, 4.3277e-01, 4.0298e-02,\n",
       "            5.0095e-01],\n",
       "           [9.2920e-01, 2.6540e-01, 5.0192e-01, 6.7080e-01, 8.5448e-01,\n",
       "            7.1835e-01]],\n",
       "\n",
       "          [[2.0776e-01, 3.5813e-01, 8.3567e-01, 4.7063e-01, 4.0508e-01,\n",
       "            9.5589e-01],\n",
       "           [5.8947e-01, 9.4760e-01, 6.0232e-01, 7.2052e-01, 3.9262e-01,\n",
       "            7.1562e-01],\n",
       "           [1.0725e-02, 4.4866e-01, 9.7443e-01, 2.9959e-01, 1.4513e-01,\n",
       "            1.2928e-01],\n",
       "           [2.9089e-01, 1.3430e-01, 8.0785e-01, 1.2497e-01, 8.8492e-01,\n",
       "            3.6927e-01],\n",
       "           [5.9389e-01, 9.6282e-01, 6.2506e-01, 5.3792e-01, 7.0559e-01,\n",
       "            7.4136e-01]],\n",
       "\n",
       "          [[5.0197e-01, 6.6981e-02, 1.2605e-01, 4.9837e-01, 7.4453e-01,\n",
       "            5.8333e-01],\n",
       "           [5.8500e-02, 4.7278e-01, 4.4585e-01, 3.9348e-01, 2.9299e-01,\n",
       "            2.4644e-01],\n",
       "           [4.9062e-01, 1.7453e-02, 8.8370e-01, 9.2474e-01, 4.6910e-01,\n",
       "            9.3207e-01],\n",
       "           [8.1975e-01, 7.5407e-01, 1.5757e-01, 9.0524e-01, 1.4111e-01,\n",
       "            9.2372e-01],\n",
       "           [5.9051e-01, 1.5849e-01, 9.9551e-01, 1.0695e-01, 5.9698e-01,\n",
       "            5.6851e-01]],\n",
       "\n",
       "          [[4.4909e-01, 2.3893e-01, 8.7608e-01, 8.3275e-01, 4.9656e-01,\n",
       "            5.2940e-01],\n",
       "           [8.9067e-01, 1.0772e-01, 7.1177e-02, 1.8795e-01, 3.7209e-01,\n",
       "            7.7108e-02],\n",
       "           [3.8127e-01, 4.8698e-01, 1.3844e-02, 2.4253e-01, 9.5876e-01,\n",
       "            2.7993e-01],\n",
       "           [8.1574e-01, 3.2932e-01, 9.3643e-01, 3.6281e-01, 2.9723e-02,\n",
       "            3.5718e-02],\n",
       "           [5.1942e-01, 7.4644e-01, 8.9526e-01, 3.9339e-01, 4.6579e-01,\n",
       "            3.7760e-01]]],\n",
       "\n",
       "\n",
       "         [[[6.0419e-01, 2.5219e-01, 8.9481e-01, 9.3241e-01, 5.2545e-01,\n",
       "            1.6303e-01],\n",
       "           [6.7860e-01, 9.2651e-01, 9.1464e-01, 2.5554e-01, 2.0435e-01,\n",
       "            3.1585e-01],\n",
       "           [4.6387e-01, 8.0291e-03, 8.1938e-01, 1.4376e-01, 9.1168e-01,\n",
       "            4.3032e-01],\n",
       "           [8.6157e-01, 7.7684e-01, 2.3211e-01, 9.8776e-01, 5.5755e-01,\n",
       "            7.9548e-01],\n",
       "           [7.2537e-01, 5.1227e-01, 2.4594e-01, 5.6658e-01, 1.9668e-01,\n",
       "            3.4684e-02]],\n",
       "\n",
       "          [[5.0704e-01, 8.0742e-01, 5.7117e-01, 1.7939e-01, 3.0070e-01,\n",
       "            3.3660e-01],\n",
       "           [4.9959e-01, 1.4129e-01, 7.9704e-01, 3.2192e-01, 9.2205e-01,\n",
       "            4.5943e-02],\n",
       "           [5.5711e-01, 8.2523e-01, 1.5307e-01, 9.2242e-01, 7.6464e-01,\n",
       "            5.5727e-01],\n",
       "           [6.5204e-01, 5.1727e-01, 9.4230e-01, 7.0124e-01, 7.6757e-01,\n",
       "            7.7841e-01],\n",
       "           [5.6839e-01, 2.7299e-01, 6.5643e-01, 9.8751e-02, 2.4366e-01,\n",
       "            6.1813e-01]],\n",
       "\n",
       "          [[6.2689e-01, 9.9511e-01, 1.1922e-01, 5.5689e-01, 8.4489e-01,\n",
       "            1.4568e-01],\n",
       "           [5.4566e-01, 5.5511e-01, 8.3434e-01, 5.3940e-01, 3.0012e-01,\n",
       "            1.9686e-01],\n",
       "           [7.2224e-01, 3.0446e-01, 6.3587e-01, 4.6250e-01, 3.7259e-01,\n",
       "            6.0364e-01],\n",
       "           [3.5991e-01, 2.8139e-01, 8.9241e-01, 4.1124e-01, 6.4380e-01,\n",
       "            2.8630e-01],\n",
       "           [9.3336e-01, 7.7449e-01, 1.2771e-01, 2.5839e-02, 6.8242e-01,\n",
       "            4.5306e-01]],\n",
       "\n",
       "          [[2.3508e-01, 3.2443e-01, 2.4340e-01, 2.5368e-01, 7.3877e-02,\n",
       "            2.7976e-01],\n",
       "           [3.4373e-01, 6.2581e-01, 6.7954e-01, 6.3737e-01, 1.7564e-01,\n",
       "            8.6121e-01],\n",
       "           [4.4189e-01, 8.2449e-01, 4.3858e-01, 9.6664e-01, 5.2556e-01,\n",
       "            8.8414e-02],\n",
       "           [6.6331e-01, 8.7454e-01, 1.9358e-02, 2.9720e-01, 2.1860e-01,\n",
       "            3.4142e-01],\n",
       "           [7.0265e-01, 5.3002e-01, 4.8642e-01, 9.6334e-02, 8.7510e-01,\n",
       "            1.5107e-01]]],\n",
       "\n",
       "\n",
       "         [[[5.7575e-01, 2.1861e-01, 7.5952e-01, 9.4151e-01, 3.2599e-01,\n",
       "            7.4858e-01],\n",
       "           [3.1499e-01, 4.3711e-01, 8.3259e-01, 5.4567e-02, 1.2523e-01,\n",
       "            9.5581e-01],\n",
       "           [9.0021e-01, 5.7687e-02, 4.9708e-01, 5.1924e-01, 2.3567e-01,\n",
       "            8.1409e-01],\n",
       "           [9.3362e-01, 9.2832e-01, 7.2941e-01, 9.0121e-01, 2.2331e-01,\n",
       "            8.4739e-01],\n",
       "           [5.9016e-01, 7.3108e-01, 8.5674e-01, 8.1974e-01, 1.1541e-01,\n",
       "            1.5955e-01]],\n",
       "\n",
       "          [[4.6095e-01, 6.3393e-01, 1.4336e-01, 1.4166e-01, 6.7390e-01,\n",
       "            6.5047e-01],\n",
       "           [3.3304e-03, 1.4263e-01, 6.5982e-01, 7.4128e-01, 8.8050e-02,\n",
       "            6.8226e-01],\n",
       "           [3.5860e-01, 1.7257e-01, 1.1969e-01, 5.5839e-01, 8.8673e-01,\n",
       "            3.5584e-05],\n",
       "           [9.3165e-01, 1.5637e-01, 7.1092e-01, 8.7692e-02, 3.2796e-01,\n",
       "            3.2905e-01],\n",
       "           [7.0813e-01, 9.2097e-01, 5.7843e-01, 7.6961e-01, 5.8211e-01,\n",
       "            5.0080e-01]],\n",
       "\n",
       "          [[1.9027e-01, 1.0105e-01, 1.2287e-01, 9.5423e-02, 6.9237e-01,\n",
       "            8.7493e-01],\n",
       "           [7.5896e-01, 7.4925e-02, 7.9105e-01, 3.1422e-01, 1.0819e-02,\n",
       "            2.7366e-01],\n",
       "           [9.4491e-01, 2.0969e-02, 8.9298e-01, 6.9346e-01, 2.9373e-01,\n",
       "            2.1869e-01],\n",
       "           [6.2187e-01, 4.0168e-01, 8.3432e-01, 3.9705e-01, 8.7023e-02,\n",
       "            5.2169e-01],\n",
       "           [7.7491e-01, 1.9770e-01, 5.1723e-01, 3.3704e-01, 1.7271e-01,\n",
       "            3.1860e-01]],\n",
       "\n",
       "          [[5.4011e-01, 1.8611e-02, 9.3700e-01, 1.0364e-01, 3.9308e-01,\n",
       "            7.9605e-01],\n",
       "           [2.6220e-01, 5.4887e-01, 5.0158e-01, 3.5716e-01, 9.4585e-01,\n",
       "            4.2351e-02],\n",
       "           [2.8432e-01, 2.7649e-01, 2.1234e-02, 3.5664e-01, 9.8422e-01,\n",
       "            2.2707e-01],\n",
       "           [4.7082e-01, 7.2006e-01, 3.2282e-01, 7.1515e-01, 6.6139e-01,\n",
       "            9.3834e-01],\n",
       "           [5.9158e-01, 8.5758e-01, 9.6491e-01, 4.1371e-01, 5.1623e-01,\n",
       "            2.5058e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[2.8854e-01, 1.9074e-01, 7.1863e-01, 7.5536e-02, 7.3829e-02,\n",
       "            5.2000e-01],\n",
       "           [4.7825e-01, 5.0205e-01, 8.6258e-01, 6.4783e-01, 5.0973e-01,\n",
       "            5.1878e-01],\n",
       "           [6.6096e-01, 7.4818e-01, 2.8291e-01, 4.0345e-01, 7.8631e-01,\n",
       "            4.4220e-01],\n",
       "           [6.9412e-01, 7.1236e-01, 3.2863e-01, 4.5331e-01, 6.8094e-01,\n",
       "            8.2802e-01],\n",
       "           [3.9753e-01, 2.5900e-01, 6.3743e-01, 3.8097e-01, 2.9492e-03,\n",
       "            6.4242e-02]],\n",
       "\n",
       "          [[7.6146e-01, 6.9553e-01, 1.3793e-01, 3.3968e-02, 6.0064e-01,\n",
       "            9.3847e-01],\n",
       "           [4.6523e-01, 5.1328e-01, 2.7252e-02, 8.6393e-01, 8.5397e-01,\n",
       "            4.0613e-01],\n",
       "           [1.3759e-01, 5.7511e-01, 6.4576e-02, 6.4195e-01, 6.4610e-01,\n",
       "            6.1606e-02],\n",
       "           [3.7323e-01, 6.8681e-01, 2.7664e-02, 5.6718e-01, 3.3487e-01,\n",
       "            4.8493e-01],\n",
       "           [7.1986e-01, 4.3476e-01, 9.7350e-01, 1.0729e-01, 8.5084e-01,\n",
       "            7.1764e-01]],\n",
       "\n",
       "          [[4.8586e-01, 5.4673e-01, 2.3436e-01, 2.8198e-01, 7.9855e-01,\n",
       "            2.9093e-01],\n",
       "           [4.7823e-01, 4.7569e-01, 6.5488e-01, 4.9140e-01, 1.5257e-01,\n",
       "            9.4835e-01],\n",
       "           [9.2440e-01, 4.3764e-01, 2.2936e-01, 5.7119e-01, 4.5584e-01,\n",
       "            1.8916e-01],\n",
       "           [8.3558e-01, 5.2500e-01, 4.2056e-01, 2.8006e-01, 9.3832e-01,\n",
       "            2.0341e-01],\n",
       "           [2.1591e-01, 7.9492e-01, 6.4828e-01, 7.6345e-01, 2.9132e-01,\n",
       "            7.8969e-01]],\n",
       "\n",
       "          [[1.7433e-01, 8.4795e-01, 6.5305e-01, 6.9236e-01, 2.7207e-01,\n",
       "            7.8810e-01],\n",
       "           [9.2139e-01, 5.7155e-01, 7.1879e-01, 8.9485e-02, 5.2615e-01,\n",
       "            9.7358e-01],\n",
       "           [5.0845e-01, 4.3103e-01, 8.6168e-01, 8.0914e-01, 2.4198e-01,\n",
       "            7.3668e-02],\n",
       "           [1.9947e-01, 5.8106e-01, 5.1278e-01, 5.2345e-01, 2.7933e-02,\n",
       "            9.0041e-01],\n",
       "           [6.7043e-02, 1.8039e-01, 6.2293e-01, 8.4956e-01, 8.7144e-01,\n",
       "            1.3861e-01]]],\n",
       "\n",
       "\n",
       "         [[[4.8320e-01, 6.7638e-01, 6.2985e-01, 1.9342e-01, 8.4566e-01,\n",
       "            7.6565e-01],\n",
       "           [4.2527e-01, 2.8831e-01, 9.5144e-02, 9.0095e-02, 5.8690e-01,\n",
       "            2.6336e-02],\n",
       "           [4.9940e-01, 5.1402e-01, 7.0176e-01, 7.4067e-01, 5.2569e-01,\n",
       "            4.1608e-01],\n",
       "           [7.1837e-01, 2.3024e-01, 3.4193e-01, 9.8916e-01, 4.2335e-01,\n",
       "            9.5509e-01],\n",
       "           [7.4062e-01, 9.9922e-01, 7.1269e-01, 3.3301e-01, 2.9999e-01,\n",
       "            6.9151e-01]],\n",
       "\n",
       "          [[9.3183e-01, 1.7587e-01, 7.7702e-01, 1.3497e-01, 9.2003e-01,\n",
       "            2.0218e-01],\n",
       "           [8.5235e-01, 9.8030e-01, 9.3893e-02, 2.0264e-01, 4.3448e-01,\n",
       "            3.3691e-01],\n",
       "           [9.1995e-01, 2.3747e-01, 3.9837e-01, 3.4175e-02, 8.7417e-01,\n",
       "            4.6161e-01],\n",
       "           [3.6421e-01, 5.7382e-01, 2.8478e-01, 1.3927e-02, 3.1997e-01,\n",
       "            7.5656e-01],\n",
       "           [6.4469e-01, 8.6405e-01, 4.9925e-01, 3.1600e-01, 1.9332e-01,\n",
       "            5.9939e-01]],\n",
       "\n",
       "          [[3.8248e-01, 5.9398e-01, 5.9356e-01, 9.1622e-01, 7.7809e-01,\n",
       "            2.0012e-01],\n",
       "           [7.7152e-01, 3.5574e-01, 2.9537e-01, 5.6542e-01, 5.2425e-01,\n",
       "            6.6099e-01],\n",
       "           [4.9001e-01, 9.3928e-02, 4.3854e-01, 8.8885e-01, 8.9925e-01,\n",
       "            5.2877e-01],\n",
       "           [1.5712e-01, 5.8408e-01, 1.1796e-01, 4.0614e-01, 9.1208e-01,\n",
       "            2.0657e-01],\n",
       "           [2.2819e-01, 5.9535e-01, 2.8785e-01, 3.1635e-01, 2.4604e-01,\n",
       "            1.0069e-01]],\n",
       "\n",
       "          [[4.4411e-03, 9.5851e-02, 3.4643e-02, 4.6127e-01, 9.6181e-01,\n",
       "            6.3235e-01],\n",
       "           [7.3319e-01, 8.0828e-01, 3.7567e-01, 8.6280e-01, 1.0496e-01,\n",
       "            4.5588e-01],\n",
       "           [5.5591e-01, 9.4227e-01, 5.1693e-01, 8.5222e-01, 7.8673e-01,\n",
       "            5.9873e-01],\n",
       "           [4.3773e-01, 5.1705e-02, 7.3068e-01, 2.9392e-01, 9.8673e-01,\n",
       "            8.2561e-01],\n",
       "           [1.5732e-01, 5.2844e-01, 2.9241e-01, 9.3971e-01, 8.5387e-01,\n",
       "            9.8756e-01]]],\n",
       "\n",
       "\n",
       "         [[[2.0547e-01, 7.5116e-01, 2.6867e-01, 9.9190e-01, 4.5260e-01,\n",
       "            6.6474e-01],\n",
       "           [2.3458e-01, 9.9267e-01, 3.9249e-01, 3.9672e-01, 4.6246e-01,\n",
       "            7.5896e-01],\n",
       "           [2.3643e-01, 5.1343e-01, 8.5611e-01, 6.6499e-01, 5.1118e-01,\n",
       "            4.3090e-01],\n",
       "           [3.5890e-01, 5.9525e-01, 1.0460e-02, 8.6172e-01, 1.7852e-01,\n",
       "            9.4269e-01],\n",
       "           [2.2274e-01, 6.8975e-01, 8.0092e-01, 8.8996e-01, 5.5309e-01,\n",
       "            9.8923e-01]],\n",
       "\n",
       "          [[1.9579e-01, 8.0932e-02, 8.0132e-01, 5.6708e-01, 4.7948e-01,\n",
       "            3.4948e-01],\n",
       "           [2.6399e-01, 6.6361e-01, 4.4572e-01, 6.1647e-01, 7.1364e-01,\n",
       "            6.8653e-01],\n",
       "           [8.2603e-02, 8.8569e-01, 7.4146e-01, 7.3482e-01, 7.3498e-01,\n",
       "            6.7751e-01],\n",
       "           [4.6997e-01, 5.1148e-01, 7.4660e-01, 1.1923e-01, 5.4714e-02,\n",
       "            4.1587e-01],\n",
       "           [8.7627e-01, 8.9539e-01, 5.1180e-01, 5.9259e-01, 9.2143e-01,\n",
       "            9.9951e-01]],\n",
       "\n",
       "          [[8.3249e-03, 3.4950e-01, 1.2152e-01, 8.1353e-01, 7.9114e-01,\n",
       "            8.8587e-01],\n",
       "           [4.4977e-01, 5.6560e-01, 1.2657e-01, 9.1113e-01, 7.0741e-01,\n",
       "            6.4049e-01],\n",
       "           [2.1493e-02, 1.3605e-01, 4.1175e-01, 1.9037e-01, 3.1032e-01,\n",
       "            4.5454e-01],\n",
       "           [7.2397e-01, 4.8064e-01, 7.0546e-02, 7.1700e-01, 8.3853e-01,\n",
       "            8.1999e-01],\n",
       "           [2.5076e-02, 3.2652e-01, 3.2241e-01, 9.8147e-01, 5.0186e-01,\n",
       "            1.5395e-01]],\n",
       "\n",
       "          [[5.8587e-01, 3.8618e-01, 9.5993e-01, 1.3644e-01, 2.3184e-01,\n",
       "            2.2519e-01],\n",
       "           [1.9090e-01, 9.8505e-01, 8.6195e-01, 3.5747e-01, 5.4899e-01,\n",
       "            6.9387e-01],\n",
       "           [6.0816e-01, 2.8098e-01, 4.4838e-01, 7.5155e-01, 8.9436e-01,\n",
       "            3.3905e-01],\n",
       "           [7.5708e-01, 4.2045e-01, 7.3210e-01, 2.2499e-01, 8.2295e-01,\n",
       "            1.3676e-03],\n",
       "           [3.5703e-01, 6.0164e-01, 9.1408e-01, 1.7244e-01, 6.0089e-01,\n",
       "            1.6891e-03]]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5d random tensor\n",
    "rand5dtensor=torch.rand(2,3,4,5,6)\n",
    "rand5dtensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zero tensor\n",
    "zero_tensor=torch.zeros(3,3,3)\n",
    "zero_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#float 16 tensor\n",
    "float16_tensor=torch.zeros(3,3,3,dtype=torch.float16)\n",
    "float16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#float 64 tensor\n",
    "float64_tensor=torch.zeros(3,3,3,dtype=torch.float64)\n",
    "float64_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor*float64_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int tensor\n",
    "int_tensor=torch.tensor([1,2,3,4,5])#default int tensor is int64\n",
    "int_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#32 bit int tensor\n",
    "int32_tensor=torch.tensor([1,2,3,4,5],dtype=torch.int32)#for 16 bit use torch.int16 and for 64 bit use torch.int64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def function to check dtype device and shape of tensor\n",
    "def describe_tensor(tensor):\n",
    "    print(f\"Shape of tensor: {tensor.shape}\")\n",
    "    print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "    print(f\"Device tensor is stored on: {tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([5])\n",
      "Datatype of tensor: torch.int32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "describe_tensor(int32_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor manipulating\n",
    "\n",
    "tensor opretions include:\n",
    "* airthmatic alzebra\n",
    "* matrix multipliction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#addition\n",
    "int_tensor=torch.tensor([1,2,3,4,5])\n",
    "int_tensor+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiplication\n",
    "int_tensor*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#by pytorch inbuilt function\n",
    "torch.add(int_tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(int_tensor,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matrix multiplication\n",
    "* matrix multiplication \n",
    "* elemental multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 10,  40,  90, 160, 250])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element wise multiplication\n",
    "a=torch.tensor([1,2,3,4,5])\n",
    "b=torch.tensor([10,20,30,40,50])\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) * tensor([[10, 20, 30],\n",
      "        [40, 50, 60]])\n",
      "equals:tensor([[ 10,  40,  90],\n",
      "        [160, 250, 360]])\n"
     ]
    }
   ],
   "source": [
    "# element wise multiplication in 2d tensor\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "b=torch.tensor([[10,20,30],[40,50,60]])\n",
    "print(a,'*',b,)\n",
    "print(f\"equals:{a*b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[220, 280],\n",
       "        [490, 640]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix multiplication\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])#2x3\n",
    "b=torch.tensor([[10,20],[30,40],[50,60]])#3x2\n",
    "torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stat of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([2, 3])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n",
      "Mean: 3.5\n",
      "Max: 6.0\n",
      "Min: 1.0\n",
      "Sum: 21.0\n",
      "Standard Deviation: 1.8708287477493286\n"
     ]
    }
   ],
   "source": [
    "# finding mean, max, min, sum, std 2d tensor\n",
    "def stat_tensor(tensor):\n",
    "    print(f\"Shape of tensor: {tensor.shape}\")\n",
    "    print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "    print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "    print(f\"Mean: {tensor.mean()}\")# means works on float tensor\n",
    "    print(f\"Max: {tensor.max()}\")\n",
    "    print(f\"Min: {tensor.min()}\")\n",
    "    print(f\"Sum: {tensor.sum()}\")\n",
    "    print(f\"Standard Deviation: {tensor.std()}\")\n",
    "a=torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "stat_tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([2, 3])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n",
      "Max: 6.0\n",
      "Position of Max: 5\n",
      "Min: 1.0\n",
      "Position of Min: 0\n"
     ]
    }
   ],
   "source": [
    "# finding positional max and min\n",
    "def pos_max_min(tensor):\n",
    "    print(f\"Shape of tensor: {tensor.shape}\")\n",
    "    print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "    print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "    print(f\"Max: {tensor.max()}\")\n",
    "    print(f\"Position of Max: {tensor.argmax()}\")\n",
    "    print(f\"Min: {tensor.min()}\")\n",
    "    print(f\"Position of Min: {tensor.argmin()}\")\n",
    "a=torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]])\n",
    "pos_max_min(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshaping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped to 3,2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(\"reshaped to 3,2\")\n",
    "z=a.reshape(3,2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viewed to 3,2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view changes the shape of tensor\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(\"viewed to 3,2\")\n",
    "view_a=a.view(3,2)\n",
    "view_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial a tensor tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "chaning view_a will change a tensor([[100,   2,   3],\n",
      "        [  4,   5,   6]])\n"
     ]
    }
   ],
   "source": [
    "print(\"initial a tensor\",a)\n",
    "view_a[0,0]=100\n",
    "print(\"chaning view_a will change a\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stacking tensors\n",
    "a=torch.tensor([1,2,3])\n",
    "b=torch.tensor([4,5,6])\n",
    "torch.stack((a,b),dim=0)#dimention 0 means stacking row wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((a,b),dim=1)#dimention 1 means stacking column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]],\n",
       "\n",
       "        [[ 7,  8,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stacking 2d tensors to 3d tensor\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "b=torch.tensor([[7,8,9],[10,11,12]])\n",
    "torch.stack((a,b),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]]) torch.Size([1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('squezed',\n",
       " tensor([[1, 2, 3],\n",
       "         [4, 5, 6]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SQUEEZING AND UNSQUEEZING TENSORS\n",
    "a=torch.tensor([[[1,2,3],[4,5,6]]])\n",
    "print(a,a.shape)\n",
    "\"squezed\",a.squeeze(),a.squeeze().shape#removes the dimension of size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('unsqueezed',\n",
       " tensor([[[1, 2, 3],\n",
       "          [4, 5, 6]]]),\n",
       " torch.Size([1, 2, 3]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch unsquezzing\n",
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(a,a.shape)\n",
    "\"unsqueezed\",a.unsqueeze(dim=0),a.unsqueeze(dim=0).shape#adds a dimension of size 1 at the specified position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_org shape torch.Size([2, 3, 4]) x_permute shape torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# permute - rearranges the dimensions of tensor eg: 3d tensor to 2d tensor\n",
    "x_org=torch.rand(2,3,4)#3d tensor of size 224x224x3 indicating 224x224 image with 3 channels(hieght, width, channels)\n",
    "# we permute the tensor to 3x224x224\n",
    "x_permute=x_org.permute(2,0,1)#(2=channels, 0=height, 1=width)\n",
    "print(\"x_org shape\",x_org.shape,\"x_permute shape\",x_permute.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexing and slicing\n",
    "* same as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor(5)\n",
      "tensor([[3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x=torch.arange(6).view(2,3)\n",
    "print(x)\n",
    "print(x[1,2])#indexing\n",
    "print(x[1:])#slicing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
